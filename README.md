# üîß Entorno de Orquestaci√≥n IA + Automatizaci√≥n

Este entorno contiene una arquitectura compuesta por m√∫ltiples servicios para habilitar procesamiento de lenguaje natural con **Ollama**, automatizaci√≥n de flujos con **n8n**, persistencia con **PostgreSQL**, motor vectorial **Qdrant**, almacenamiento temporal con **Redis** y backend especializado **Evolution API**. 

## üß± Servicios Incluidos

| Servicio        | Prop√≥sito |
|----------------|----------|
| `postgres`     | Base de datos relacional para n8n y Evolution API |
| `evolution_api`| API de backend desarrollada en Go para gesti√≥n de flujos Evolution |
| `redis`        | Almacenamiento temporal tipo clave/valor usado por Evolution |
| `n8n`          | Plataforma de automatizaci√≥n de flujos |
| `qdrant`       | Base de datos vectorial para b√∫squedas sem√°nticas |
| `ollama`       | Motor local de modelos de lenguaje (Llama 3.1, Nomic Embed) |

## üì¶ Pre-requisitos

Antes de ejecutar el entorno, asegurese de contar con:

1. [Docker](https://docs.docker.com/get-docker/) 
2. [Docker Compose](https://docs.docker.com/compose/install/) 
3. Soporte opcional para GPU con [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) si desea usar el perfil `gpu-nvidia`  
4. Archivo `.env` con las siguientes variables definidas:

```env
POSTGRES_USER=usuario
POSTGRES_PASSWORD=clave
POSTGRES_DB=n8n
N8N_ENCRYPTION_KEY=clave_secreta
N8N_USER_MANAGEMENT_JWT_SECRET=otra_clave
```

## üöÄ Instalaci√≥n

1. Clonar el repositorio:

```bash
git clone https://github.com/Jaliko05/Ollama-n8n-evolution_api.git
cd mi-repo
```

2. Crear archivo `.env` con las variables requeridas (ver secci√≥n anterior).

3. Iniciar servicios (modo CPU por defecto):

```bash
docker compose --profile cpu up -d
```

Para usar la versi√≥n con aceleraci√≥n por GPU:

```bash
docker compose --profile gpu-nvidia up -d
```

> ‚ö†Ô∏è Recuerde que el modelo Llama3.1 y el embedder `nomic-embed-text` se descargan autom√°ticamente al iniciar el contenedor `ollama-pull-llama-*`.

## üï∏Ô∏è Red y Vol√∫menes

Todos los servicios est√°n conectados a una red llamada `evo_n8n_net`. Los datos persistentes se almacenan en vol√∫menes Docker:

- `n8n_storage`
- `postgres_data`
- `qdrant_storage`
- `evolution_instances`
- `evolution_redis`
- `ollama_storage`

## üìç Puertos Expuestos

| Servicio     | Puerto Local | Descripci√≥n |
|--------------|--------------|-------------|
| PostgreSQL   | `5432`       | Base de datos |
| Evolution API| `8080`       | Backend API |
| Redis        | `6379`       | Almacenamiento en memoria |
| n8n          | `5678`       | Interfaz web de automatizaciË¥∏n |
| Qdrant       | `6333`       | API REST vectorial |
| Ollama       | `11434`      | Servicio LLM local |

## üß™ Verificaci√≥n

Puede verificar que los servicios est√°n corriendo:

```bash
docker compose ps
```

Y acceder a:

- n8n: http://localhost:5678
- Evolution API: http://localhost:8080
- Qdrant: http://localhost:6333
- Ollama: http://localhost:11434

## üßπ Apagar servicios

```bash
docker compose down
```

## üõ†Ô∏èNotas adicionales

- `ollama-pull-llama-*` son contenedores de inicializaci√≥n dise√±ados para descargar modelos. Se auto detienen tras finalizar.
- El entorno est√° pensado para ser extensible. Puede agregar nuevos modelos Ollama simplemente modificando la l√≠nea de `pull`.

## üìù Licencia

Este proyecto compone y orquesta servicios de terceros a trav√©s de im√°genes oficiales disponibles p√∫blicamente. Cada servicio (Ollama, Qdrant, n8n, Redis, PostgreSQL, etc.) est√° sujeto a su propia licencia de uso, la cual puede revisarse en los respectivos repositorios oficiales:

- [Ollama](https://github.com/ollama/ollama) ‚Äì Licencia espec√≠fica de Ollama
- [Qdrant](https://github.com/qdrant/qdrant) ‚Äì Apache 2.0
- [n8n](https://github.com/n8n-io/n8n) ‚Äì Sustainable Use License (SUL)
- [Redis](https://github.com/redis/redis) ‚Äì BSD 3-Clause
- [PostgreSQL](https://www.postgresql.org/about/licence/) ‚Äì PostgreSQL License
- [Evolution API](https://github.com/atendai/evolution-api) ‚Äì Licencia seg√∫n proveedor

Este `docker-compose` no modifica, redistribuye ni empaqueta estos servicios, solo automatiza su despliegue. Se recomienda revisar cada repositorio antes de su uso en producci√≥n.

